# Default config file for spark job process
app {
  oDate: "2019-05-08",
  process: "D"
  paramLocal {
    environment = "U"
    module = "cptInvoices"
    numCoalesce = "100"
    overwrite = "overwrite"
    efectPortfolio = "CA"
    highPayrolls = "502"
    confirming = "27"
    accountBrand = "C"
    cardBrand = "T"
    digitContract = "0"
    digitVisa = "4"
    digitMastercard = "5"
  }
  inputs {
    manager {
      paths = ["src/test/resources/data/input/t_mdco_tcom_manager"]
      type = parquet
      information_date = ${?DATE1}
    }
    structure {
      paths = ["src/test/resources/data/input/t_mdco_branch_structure"]
      type = parquet
       cutoff_date = ${?DATE2}
    }
  }
  outputs{
    outputFinal {
      mode = reprocess
      reprocess = ["information_date="${?DATE1}]
      coalesce {
        partitions = 1
      }
      partition = [
        "information_date"
      ]
      path = "src/test/resources/data/output/punct/t_mbmi_beyg_manager2"
      schema {
        path = "src/test/resources/data/schemas/beygmanager.output-2.schema"
      }
      type = parquet
    }

  }
}
sparkMetrics {

  listeners = ["default"]

  output {
    type = "console"
  }
}

